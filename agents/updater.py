from __future__ import annotations

# ---------------------------------------------------------------------------
# Explicit question patterns for common clinical phrases TF-IDF can't paraphrase
# Maps regex pattern → list of symptom names to add as targets
# ---------------------------------------------------------------------------
import re as _re

QUESTION_PATTERNS = [
    # Radiating pain
    (_re.compile(r"radiat|left arm|arm pain|down (your |the )?arm", _re.I),
     ["radiating arm pain"]),
    # Shortness of breath
    (_re.compile(r"short of breath|breath(ing)? (difficult|problem|trouble)|"
                 r"dyspne|out of breath|can.t breathe", _re.I),
     ["shortness of breath"]),
    # Chest pain / tightness
    (_re.compile(r"chest (pain|tight|pressure|discomfort|hurt)", _re.I),
     ["chest pain", "chest tightness"]),
    # Exertional symptoms
    (_re.compile(r"(stairs|exercis|exert|walk|climb|physical)", _re.I),
     ["exertional chest pain", "shortness of breath"]),
    # Palpitations
    (_re.compile(r"heart (rac|pound|flutter|beat fast|skip)|palpit", _re.I),
     ["palpitations", "rapid heart rate"]),
    # Dizziness / syncope
    (_re.compile(r"dizz|lightheaded|faint|syncope|pass(ing)? out|blackout", _re.I),
     ["dizziness", "fainting"]),
    # Swelling
    (_re.compile(r"swell(ing)?|oedema|edema|puffy|fluid", _re.I),
     ["leg swelling"]),
    # Cough types
    (_re.compile(r"(dry|wet|productive|blood(y)?|persistent) cough|cough(ing)? up", _re.I),
     ["cough", "chronic cough"]),
    # Fever
    (_re.compile(r"fever|temperature|pyrexia|febrile|hot|chills", _re.I),
     ["fever", "chills"]),
    # Night sweats
    (_re.compile(r"night sweat|sweat(ing)? at night|wake up (soaked|drenched)", _re.I),
     ["sweating", "night sweats"]),
    # Appetite / weight
    (_re.compile(r"appetite|hunger|eating|weight (loss|gain|drop|increase)", _re.I),
     ["loss of appetite", "unexplained weight loss", "weight gain"]),
    # Headache / migraine
    (_re.compile(r"head(ache|pain)|migrain|throbbing head", _re.I),
     ["headache"]),
    # Nausea / vomiting
    (_re.compile(r"nausea|vomit|sick to (your|the) stomach|throw(ing)? up", _re.I),
     ["nausea", "vomiting"]),
    # Fatigue
    (_re.compile(r"tired|fatigue|exhausted|no energy|weak|lethar", _re.I),
     ["fatigue", "weakness"]),
    # Urination
    (_re.compile(r"urinat|pee|peeing|bladder|burning when", _re.I),
     ["frequent urination", "burning urination"]),
    # Joint / muscle pain
    (_re.compile(r"joint|arthral|muscle (pain|ache|hurt)|myalg|stiff(ness)?", _re.I),
     ["joint pain", "muscle aches"]),
    # Vision
    (_re.compile(r"vision|blurr|sight|see (double|blurry)", _re.I),
     ["blurred vision"]),
]

"""
updater.py
----------
Sequential Bayesian updating of candidate diagnoses through a Q&A session.
Questions are generated by QuestionStrategy (open-ended clinical questions).
Answers are parsed by FreeTextAnswerParser (free natural language).
"""

import numpy as np
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Literal, Union

from agents.scorer import (CandidateDiagnosis, _normalise, _tokenise,
                    RNG, MC_SAMPLES, W_SYMPTOMS, W_RISK, W_PRIOR,
                    beta_variance_confidence)
from agents.answer_parser import FreeTextAnswerParser, ParsedAnswer
from agents.question_strategy import QuestionStrategy, Question

AnswerType = Literal["yes","no","mild","unsure","skip"]

ANSWER_WEIGHTS: Dict[str, tuple] = {
    "yes":   (1.0, 0.0),
    "no":    (0.0, 1.0),
    "mild":  (0.5, 0.0),
    "unsure":(0.2, 0.2),
    "skip":  (0.0, 0.0),
}
K_CONF = 6.0


# ---------------------------------------------------------------------------
# Per-disease mutable Bayesian state
# ---------------------------------------------------------------------------

@dataclass
class DiseaseState:
    disease:     str
    sym_alpha:   float
    sym_beta:    float
    rf_alpha:    float
    rf_beta:     float
    prior:       float
    evidence_n:  int
    sym_profile: List[str]
    rf_profile:  List[str]
    update_log:  List[dict] = field(default_factory=list)


# ---------------------------------------------------------------------------
# IDF symptom specificity
# ---------------------------------------------------------------------------

def _build_idf(candidates: List[CandidateDiagnosis],
               profiles: Dict[str, List[str]]) -> Dict[str, float]:
    N  = len(candidates)
    df: Dict[str, int] = {}
    for syms in profiles.values():
        for s in syms:
            sn = _normalise(s)
            df[sn] = df.get(sn, 0) + 1
    return {s: np.log(N / (c+1) + 1) for s, c in df.items()}


# ---------------------------------------------------------------------------
# SequentialUpdater
# ---------------------------------------------------------------------------

class SequentialUpdater:
    """
    Maintains Bayesian state for all candidate diseases across a Q&A session.

    Usage
    -----
    updater  = SequentialUpdater(candidates, dataset_profiles)
    question = updater.next_question()           # QuestionStrategy picks best Q
    parsed, updates = updater.apply_answer(question.target_symptom, raw_text)
    candidates = updater.current_candidates()
    """

    def __init__(self,
                 candidates: List[CandidateDiagnosis],
                 dataset_profiles: Dict[str, dict],
                 sem_index=None):
        self._states: Dict[str, DiseaseState] = {}
        self._idf = _build_idf(candidates, {
            d: info["symptoms"] for d, info in dataset_profiles.items()})
        self._asked:     set[str] = set()
        self._confirmed: set[str] = set()
        self._turn = 0
        self._sem  = sem_index   # SemanticIndex for ML question parsing

        # Build free-text parser with full symptom vocab
        all_phrases: List[str] = []
        for info in dataset_profiles.values():
            all_phrases.extend(info.get("symptoms", []))
            all_phrases.extend(info.get("risk_factors", []))
        self._parser = FreeTextAnswerParser(list(set(all_phrases)))

        # Initialise DiseaseState from initial CandidateDiagnosis scores
        for c in candidates:
            prof     = dataset_profiles.get(c.disease, {})
            sym_list = [_normalise(s) for s in prof.get("symptoms", [])]
            rf_list  = [_normalise(r) for r in prof.get("risk_factors", [])]
            s_match  = c.symptom_match_exact + 0.5 * c.symptom_match_partial
            s_miss   = max(c.symptom_total - s_match, 0)
            # Inizializzazione con SOLE osservazioni attive dall'anamnesi iniziale.
            # I sintomi riportati dal paziente all'inizio (symptoms_text) sono
            # osservazioni attive -> yes. I sintomi nel profilo non menzionati
            # sono miss PASSIVI -> non contribuiscono al Beta, solo alla probabilità.
            # Questo garantisce che C=0 per malattie mai esplorate via Q&A.
            s_active_match = s_match          # sintomi riportati = yes attivi
            s_active_miss  = 0.0              # non sappiamo ancora dei miss
            rf_active_match = float(c.risk_factor_hits)
            rf_active_miss  = 0.0

            self._states[c.disease] = DiseaseState(
                disease    = c.disease,
                sym_alpha  = s_active_match + 1.0,
                sym_beta   = s_active_miss  + 1.0,
                rf_alpha   = rf_active_match + 1.0,
                rf_beta    = rf_active_miss  + 1.0,
                prior      = c.prior,
                evidence_n = c.evidence_tokens,
                sym_profile = sym_list,
                rf_profile  = rf_list,
            )

        # Build question strategy
        self._strategy = QuestionStrategy(
            self._states, self._idf, self._asked, self._confirmed)

        # SemanticIndex for ML extraction of symptoms from question text
        self._sem_index = sem_index
        self._all_symptoms: List[str] = sorted(set(
            s for info in dataset_profiles.values()
            for s in list(info.get("symptoms", [])) + list(info.get("risk_factors", []))
        ))

    # ------------------------------------------------------------------
    # Question selection
    # ------------------------------------------------------------------

    def next_question(self) -> Optional[Question]:
        return self._strategy.next_question()

    # ------------------------------------------------------------------
    # Answer application
    # ------------------------------------------------------------------

    def apply_answer(self,
                     question: "Question",
                     raw_answer: str) -> tuple[ParsedAnswer, List[dict]]:
        """
        Parse a free-text answer and update all disease states.

        TARGET EXTRACTION (ML-based)
        ----------------------------
        Target symptoms are extracted automatically from the *question text*
        using SemanticIndex — no manual tagging needed.

        Pipeline
        --------
        1. SemanticIndex.extract_symptoms_from_question(question.prompt)
           → [(symptom, similarity_score), ...]  ordered by relevance

        2. Build a polarity map for the whole answer via extract_all_mentions()
           → {symptom: (polarity, effective_strength)}

        3. For each ML-extracted target:
             - if it appears in the answer  → use its local polarity
             - if not mentioned explicitly  → apply the global answer polarity
               (the whole answer is about this symptom)
           Scale the Beta update by sim_score so high-confidence targets
           get full weight, borderline ones get partial weight.

        4. Also collect any *extra* symptom mentions in the answer that
           weren't explicit targets, at 0.6× discount weight.

        Fallback: if SemanticIndex is unavailable, falls back to
        question.target_symptom (back-compat with old Question objects).
        """
        self._turn += 1
        parsed = self._parser.parse(raw_answer)
        norm   = _normalise(raw_answer)
        symptoms_to_update: List[tuple[str, float, float]] = []

        # ── Step 1: extract targets from question text via ML ──────────
        ml_targets: List[tuple[str, float]] = []
        if self._sem is not None:
            ml_targets = self._sem.extract_symptoms_from_question(
                question.prompt, k=6, threshold=0.45)

        # Fallback: use Question's pre-set target if ML found nothing
        if not ml_targets and question.target_symptom:
            ml_targets = [(_normalise(question.target_symptom), 1.0)]

        # ── Step 2: polarity map from the full answer ───────────────────
        mentions_map: dict = {
            _normalise(sym): (pol, eff)
            for sym, pol, eff in self._parser.extract_all_mentions(norm)
        }

        if ml_targets:
            # ── Step 3: apply per-target updates ───────────────────────
            for target_sym, sim_score in ml_targets:
                sn = _normalise(target_sym)

                if sn in mentions_map:
                    # Explicitly mentioned → use local polarity from answer
                    pol, eff = mentions_map[sn]
                else:
                    # Not explicitly mentioned → apply global answer polarity
                    # ("yes definitely" after "do you have chest pain?" → yes)
                    pol = parsed.answer_type if parsed.answer_type != "skip" else "unsure"
                    eff = parsed.effective_strength

                if pol == "skip":
                    continue

                a_w, b_w = ANSWER_WEIGHTS.get(pol, (0.2, 0.2))
                idf       = self._idf.get(sn, 1.0)
                sim_w     = max(sim_score, 0.5)   # floor at 0.5 for borderline hits
                symptoms_to_update.append(
                    (sn, a_w * eff * idf * sim_w,
                         b_w * eff * idf * sim_w))
                self._asked.add(sn)
                if pol in ("yes", "mild"):
                    self._confirmed.add(sn)

            # ── Step 4: extra mentions in the answer not already covered ─
            for sym, pol, eff in self._parser.extract_all_mentions(norm):
                sn = _normalise(sym)
                if sn in self._asked:
                    continue
                a_w, b_w = ANSWER_WEIGHTS.get(pol, (0.2, 0.2))
                idf = self._idf.get(sn, 1.0)
                symptoms_to_update.append(
                    (sn, a_w * eff * idf * 0.6, b_w * eff * idf * 0.6))
                self._asked.add(sn)
                if pol in ("yes", "mild"):
                    self._confirmed.add(sn)

        else:
            # ── No targets at all: open/narrative question ──────────────
            for sym, pol, eff in self._parser.extract_all_mentions(norm):
                sn = _normalise(sym)
                if sn in self._asked:
                    continue
                a_w, b_w = ANSWER_WEIGHTS.get(pol, (0.2, 0.2))
                idf = self._idf.get(sn, 1.0)
                symptoms_to_update.append(
                    (sn, a_w * eff * idf * 0.7, b_w * eff * idf * 0.7))
                self._asked.add(sn)
                if pol in ("yes", "mild"):
                    self._confirmed.add(sn)

        # ── Apply updates to every disease state ───────────────────────
        updates: List[dict] = []
        for st in self._states.values():
            prev_p = self._prob_raw(st)
            prev_c = self._confidence(st)

            for sym_n, aw, bw in symptoms_to_update:
                if sym_n in st.sym_profile:
                    st.sym_alpha += aw; st.sym_beta += bw
                    st.evidence_n += 1
                elif sym_n in st.rf_profile:
                    st.rf_alpha  += aw; st.rf_beta  += bw
                    st.evidence_n += 1

            entry = {
                "disease":        st.disease,
                "symptoms":       [s for s, _, _ in symptoms_to_update],
                "n_updated":      sum(1 for s, _, _ in symptoms_to_update
                                      if s in st.sym_profile or s in st.rf_profile),
                "polarity":       parsed.polarity,
                "strength":       parsed.effective_strength,
                "temporal":       parsed.temporal,
                "severity":       parsed.severity,
                "ml_targets":     [s for s, _ in ml_targets],
                "delta_prob_raw": self._prob_raw(st) - prev_p,
                "delta_conf":     self._confidence(st) - prev_c,
            }
            st.update_log.append(entry)
            updates.append(entry)

        return parsed, updates


    # ------------------------------------------------------------------
    # Doctor free-text interface
    # ------------------------------------------------------------------

    def extract_targets_from_question(self, question_text: str) -> List[str]:
        """
        Extract symptom/RF target phrases from a free-text question.

        Uses the SemanticIndex for a single-pass embedding lookup:
          1. Embed the question once → q_vec
          2. Cosine similarity against ALL pre-embedded symptom vectors in one
             matrix multiply: sims = symptom_matrix @ q_vec   O(N·D)
          3. Return phrases above threshold, sorted by similarity

        This is O(1) embeddings regardless of vocabulary size, compared to
        the previous O(N) calls.  With PubMedBERT the threshold is ~0.55;
        with TF-IDF we also run synonym expansion and regex patterns as
        complementary signals since TF-IDF has weaker paraphrase recall.

        Returns [] for open/narrative questions → apply_answer() will then
        mine symptom mentions from the patient's answer text instead.
        """
        from agents.scorer import _normalise
        from agents.semantic_index import SYNONYMS
        q_norm   = _normalise(question_text)
        q_tokens = set(q_norm.split())
        found: set = set()

        # ── Primary: SemanticIndex single-pass matrix similarity ──────────
        # extract_symptoms_from_question() embeds the question once, then
        # does  sims = self._vecs @ q_vec  in one shot — the right way.
        if self._sem_index is not None:
            # Threshold: 0.55 for PubMedBERT/sentence-transformers,
            # 0.45 for TF-IDF (lower because TF-IDF is more conservative).
            backend = self._sem_index.backend_name
            threshold = 0.45 if "TF-IDF" in backend else 0.55
            hits = self._sem_index.extract_symptoms_from_question(
                question_text, k=len(self._all_symptoms), threshold=threshold
            )
            for phrase, sim in hits:
                if phrase in set(self._all_symptoms):
                    found.add(phrase)

        # ── Supplement for TF-IDF: synonym expansion + regex patterns ────
        # PubMedBERT handles paraphrase natively so these aren't needed.
        # TF-IDF misses e.g. "radiates to your arm" → "radiating arm pain".
        if self._sem_index is None or "TF-IDF" in self._sem_index.backend_name:

            # Synonym expansion
            for canonical, synonyms in SYNONYMS.items():
                all_forms = [canonical] + synonyms
                if any(_normalise(f) in q_norm for f in all_forms):
                    for sym in self._all_symptoms:
                        if canonical in sym or any(_normalise(s) in sym for s in synonyms):
                            found.add(sym)

            # Explicit patterns for common clinical paraphrases
            for pattern, target_syms in QUESTION_PATTERNS:
                if pattern.search(question_text):
                    for ts in target_syms:
                        ts_norm = _normalise(ts)
                        for sym in self._all_symptoms:
                            if ts_norm in sym or sym in ts_norm:
                                found.add(sym)

        return sorted(found)  # [] → open question

    def apply_answer_from_text(self, question_text: str,
                               raw_answer: str) -> tuple:
        """
        Entry point for external callers with a plain question string.

        Extracts symptom targets from the question automatically, then
        calls apply_answer() with a Question object carrying those targets.
        If no targets found, treats it as an open question and mines
        all symptom mentions from the answer text.

        Returns (ParsedAnswer, list-of-update-dicts).
        """
        targets = self.extract_targets_from_question(question_text)
        q = Question(
            prompt          = question_text,
            target_symptom  = targets[0] if targets else None,
            question_type   = "doctor_freetext",
        )
        return self.apply_answer(q, raw_answer)


    # ------------------------------------------------------------------
    # Read current state as CandidateDiagnosis objects
    # ------------------------------------------------------------------

    def current_candidates(self, top_k: int = 10) -> List[CandidateDiagnosis]:
        candidates = []
        for st in self._states.values():
            ss = RNG.beta(st.sym_alpha, st.sym_beta, size=MC_SAMPLES)
            rs = RNG.beta(st.rf_alpha,  st.rf_beta,  size=MC_SAMPLES)
            pn = np.clip(RNG.normal(st.prior, st.prior*0.1, MC_SAMPLES), 1e-6, 1)
            combined = W_SYMPTOMS*ss + W_RISK*rs + W_PRIOR*pn

            cand = CandidateDiagnosis(
                disease=st.disease,
                symptom_match_exact=max(0, int(round(st.sym_alpha - 1.0))),
                symptom_match_partial=0,
                symptom_total=max(1, int(round(st.sym_alpha + st.sym_beta - 2.0))),
                symptom_observed=st.evidence_n,
                risk_factor_hits=max(0, int(round(st.rf_alpha - 1.0))),
                risk_factor_total=max(1, int(round(st.rf_alpha + st.rf_beta - 2.0))),
                risk_factor_observed=0,
                prior=st.prior,
            )
            cand.samples         = combined
            cand.probability_raw = float(np.mean(combined))
            cand.prob_std        = float(np.std(combined))
            cand.prob_ci_lo      = float(np.percentile(combined, 5))
            cand.prob_ci_hi      = float(np.percentile(combined, 95))
            cand.confidence      = self._confidence(st)
            cand.evidence_tokens = st.evidence_n
            candidates.append(cand)

        total = sum(c.probability_raw for c in candidates) or 1.0
        for c in candidates:
            c.probability  = c.probability_raw / total
            c.prob_ci_lo  /= total
            c.prob_ci_hi  /= total
            c.prob_std    /= total

        candidates.sort(key=lambda c: (-c.probability, -c.confidence))
        return candidates[:top_k]

    # ------------------------------------------------------------------

    def _prob_raw(self, st: DiseaseState) -> float:
        sm = st.sym_alpha / (st.sym_alpha + st.sym_beta)
        rm = st.rf_alpha  / (st.rf_alpha  + st.rf_beta)
        return W_SYMPTOMS * sm + W_RISK * rm + W_PRIOR * st.prior

    @staticmethod
    def _confidence(st: DiseaseState) -> float:
        """
        Confidenza basata sulla varianza analitica del posterior Beta,
        usando SOLO le osservazioni attive accumulate via Q&A.

        Lo stato DiseaseState traccia separatamente le osservazioni attive:
          - sym_alpha/sym_beta partono da (1,1) e crescono solo con risposte
            esplicite del paziente (yes/no/mild/unsure a domande poste)
          - I miss passivi iniziali dello scorer NON entrano qui

        Quindi C=0 all'inizio e cresce solo con la Q&A.
        """
        return beta_variance_confidence(
            sym_alpha = st.sym_alpha,
            sym_beta  = st.sym_beta,
            rf_alpha  = st.rf_alpha,
            rf_beta   = st.rf_beta,
        )

    @property
    def turn(self) -> int:
        return self._turn

    @property
    def confirmed_symptoms(self) -> set:
        return set(self._confirmed)