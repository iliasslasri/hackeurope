"""
updater.py
----------
Sequential Bayesian updating of candidate diagnoses through a Q&A session.
Questions are generated by QuestionStrategy (open-ended clinical questions).
Answers are parsed by FreeTextAnswerParser (free natural language).
"""

from __future__ import annotations
import numpy as np
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Literal, Union

from scorer import (CandidateDiagnosis, _normalise, _tokenise,
                    RNG, MC_SAMPLES, W_SYMPTOMS, W_RISK, W_PRIOR)
from answer_parser import FreeTextAnswerParser, ParsedAnswer
from question_strategy import QuestionStrategy, Question

AnswerType = Literal["yes","no","mild","unsure","skip"]

ANSWER_WEIGHTS: Dict[str, tuple] = {
    "yes":   (1.0, 0.0),
    "no":    (0.0, 1.0),
    "mild":  (0.5, 0.0),
    "unsure":(0.2, 0.2),
    "skip":  (0.0, 0.0),
}
K_CONF = 6.0


# ---------------------------------------------------------------------------
# Per-disease mutable Bayesian state
# ---------------------------------------------------------------------------

@dataclass
class DiseaseState:
    disease:     str
    sym_alpha:   float
    sym_beta:    float
    rf_alpha:    float
    rf_beta:     float
    prior:       float
    evidence_n:  int
    sym_profile: List[str]
    rf_profile:  List[str]
    update_log:  List[dict] = field(default_factory=list)


# ---------------------------------------------------------------------------
# IDF symptom specificity
# ---------------------------------------------------------------------------

def _build_idf(candidates: List[CandidateDiagnosis],
               profiles: Dict[str, List[str]]) -> Dict[str, float]:
    N  = len(candidates)
    df: Dict[str, int] = {}
    for syms in profiles.values():
        for s in syms:
            sn = _normalise(s)
            df[sn] = df.get(sn, 0) + 1
    return {s: np.log(N / (c+1) + 1) for s, c in df.items()}


# ---------------------------------------------------------------------------
# SequentialUpdater
# ---------------------------------------------------------------------------

class SequentialUpdater:
    """
    Maintains Bayesian state for all candidate diseases across a Q&A session.

    Usage
    -----
    updater  = SequentialUpdater(candidates, dataset_profiles)
    question = updater.next_question()           # QuestionStrategy picks best Q
    parsed, updates = updater.apply_answer(question.target_symptom, raw_text)
    candidates = updater.current_candidates()
    """

    def __init__(self,
                 candidates: List[CandidateDiagnosis],
                 dataset_profiles: Dict[str, dict]):
        self._states: Dict[str, DiseaseState] = {}
        self._idf = _build_idf(candidates, {
            d: info["symptoms"] for d, info in dataset_profiles.items()})
        self._asked:     set[str] = set()
        self._confirmed: set[str] = set()
        self._turn = 0

        # Build free-text parser with full symptom vocab
        all_phrases: List[str] = []
        for info in dataset_profiles.values():
            all_phrases.extend(info.get("symptoms", []))
            all_phrases.extend(info.get("risk_factors", []))
        self._parser = FreeTextAnswerParser(list(set(all_phrases)))

        # Initialise DiseaseState from initial CandidateDiagnosis scores
        for c in candidates:
            prof     = dataset_profiles.get(c.disease, {})
            sym_list = [_normalise(s) for s in prof.get("symptoms", [])]
            rf_list  = [_normalise(r) for r in prof.get("risk_factors", [])]
            s_match  = c.symptom_match_exact + 0.5 * c.symptom_match_partial
            s_miss   = max(c.symptom_total - s_match, 0)
            self._states[c.disease] = DiseaseState(
                disease    = c.disease,
                sym_alpha  = s_match + 1.0,
                sym_beta   = s_miss  + 1.0,
                rf_alpha   = c.risk_factor_hits + 1.0,
                rf_beta    = max(c.risk_factor_total - c.risk_factor_hits, 0) + 1.0,
                prior      = c.prior,
                evidence_n = c.evidence_tokens,
                sym_profile = sym_list,
                rf_profile  = rf_list,
            )

        # Build question strategy
        self._strategy = QuestionStrategy(
            self._states, self._idf, self._asked, self._confirmed)

    # ------------------------------------------------------------------
    # Question selection
    # ------------------------------------------------------------------

    def next_question(self) -> Optional[Question]:
        return self._strategy.next_question()

    # ------------------------------------------------------------------
    # Answer application
    # ------------------------------------------------------------------

    def apply_answer(self,
                     target_symptom: Optional[str],
                     raw_answer: str) -> tuple[ParsedAnswer, List[dict]]:
        """
        Parse the free-text answer and update all disease states.

        target_symptom : the symptom the question was about (may be None for
                         context questions like timeline, lifestyle, etc.)
        raw_answer     : the patient's free-text response

        Returns (ParsedAnswer, list of per-disease update dicts).
        """
        self._turn += 1
        parsed = self._parser.parse(raw_answer)

        # Track confirmed symptoms for drill-down questions
        if target_symptom and parsed.polarity in ("yes", "mild"):
            self._confirmed.add(_normalise(target_symptom))

        updates: List[dict] = []

        # Collect all symptoms to update: primary target + any extras in the answer
        symptoms_to_update: List[tuple[str, float, float]] = []  # (symptom, a_w, b_w)

        if target_symptom and parsed.answer_type != "skip":
            a_w, b_w  = ANSWER_WEIGHTS[parsed.answer_type]
            strength  = parsed.effective_strength
            idf       = self._idf.get(_normalise(target_symptom), 1.0)
            symptoms_to_update.append((_normalise(target_symptom),
                                       a_w * strength * idf,
                                       b_w * strength * idf))

        for extra in parsed.extra_symptoms:
            en = _normalise(extra)
            if en != (target_symptom and _normalise(target_symptom)):
                eidf = self._idf.get(en, 1.0)
                symptoms_to_update.append((en, 0.5 * eidf, 0.0))
                self._asked.add(en)
                self._confirmed.add(en)

        for st in self._states.values():
            prev_p = self._prob_raw(st)
            prev_c = self._confidence(st)

            for sym_n, aw, bw in symptoms_to_update:
                in_sym = sym_n in st.sym_profile
                in_rf  = sym_n in st.rf_profile
                if in_sym:
                    st.sym_alpha += aw; st.sym_beta += bw
                elif in_rf:
                    st.rf_alpha  += aw; st.rf_beta  += bw

            # Confidence: +1 per symptom that appears in this disease's profile
            if target_symptom:
                tn = _normalise(target_symptom)
                if tn in st.sym_profile or tn in st.rf_profile:
                    st.evidence_n += 1
            for sym_n, _, _ in [(e[0], None, None) for e in symptoms_to_update[1:]]:
                if sym_n in st.sym_profile or sym_n in st.rf_profile:
                    st.evidence_n += 1

            entry = {
                "disease":         st.disease,
                "symptom":         target_symptom,
                "polarity":        parsed.polarity,
                "strength":        parsed.effective_strength,
                "temporal":        parsed.temporal,
                "severity":        parsed.severity,
                "in_profile":      bool(target_symptom and (
                                        _normalise(target_symptom) in st.sym_profile or
                                        _normalise(target_symptom) in st.rf_profile)),
                "extras":          parsed.extra_symptoms,
                "delta_prob_raw":  self._prob_raw(st) - prev_p,
                "delta_conf":      self._confidence(st) - prev_c,
            }
            st.update_log.append(entry)
            updates.append(entry)

        return parsed, updates

    # ------------------------------------------------------------------
    # Read current state as CandidateDiagnosis objects
    # ------------------------------------------------------------------

    def current_candidates(self, top_k: int = 10) -> List[CandidateDiagnosis]:
        candidates = []
        for st in self._states.values():
            ss = RNG.beta(st.sym_alpha, st.sym_beta, size=MC_SAMPLES)
            rs = RNG.beta(st.rf_alpha,  st.rf_beta,  size=MC_SAMPLES)
            pn = np.clip(RNG.normal(st.prior, st.prior*0.1, MC_SAMPLES), 1e-6, 1)
            combined = W_SYMPTOMS*ss + W_RISK*rs + W_PRIOR*pn

            cand = CandidateDiagnosis(
                disease=st.disease,
                symptom_match_exact=max(0, int(round(st.sym_alpha - 1.0))),
                symptom_match_partial=0,
                symptom_total=max(1, int(round(st.sym_alpha + st.sym_beta - 2.0))),
                symptom_observed=st.evidence_n,
                risk_factor_hits=max(0, int(round(st.rf_alpha - 1.0))),
                risk_factor_total=max(1, int(round(st.rf_alpha + st.rf_beta - 2.0))),
                risk_factor_observed=0,
                prior=st.prior,
            )
            cand.samples         = combined
            cand.probability_raw = float(np.mean(combined))
            cand.prob_std        = float(np.std(combined))
            cand.prob_ci_lo      = float(np.percentile(combined, 5))
            cand.prob_ci_hi      = float(np.percentile(combined, 95))
            cand.confidence      = self._confidence(st)
            cand.evidence_tokens = st.evidence_n
            candidates.append(cand)

        total = sum(c.probability_raw for c in candidates) or 1.0
        for c in candidates:
            c.probability  = c.probability_raw / total
            c.prob_ci_lo  /= total
            c.prob_ci_hi  /= total
            c.prob_std    /= total

        candidates.sort(key=lambda c: (-c.probability, -c.confidence))
        return candidates[:top_k]

    # ------------------------------------------------------------------

    def _prob_raw(self, st: DiseaseState) -> float:
        sm = st.sym_alpha / (st.sym_alpha + st.sym_beta)
        rm = st.rf_alpha  / (st.rf_alpha  + st.rf_beta)
        return W_SYMPTOMS * sm + W_RISK * rm + W_PRIOR * st.prior

    @staticmethod
    def _confidence(st: DiseaseState) -> float:
        return st.evidence_n / (st.evidence_n + K_CONF)

    @property
    def turn(self) -> int:
        return self._turn

    @property
    def confirmed_symptoms(self) -> set:
        return set(self._confirmed)
